{% set name = "apache-beam" %}
{% set version = "2.65.0" %}
{% set python_min = "3.9" %}

package:
  name: {{ name|lower }}-split
  version: {{ version }}

source:
  url: https://pypi.org/packages/source/{{ name[0] }}/{{ name }}/{{ name.replace('-', '_') }}-{{ version }}.tar.gz
  sha256: 91cafaa2dc6c42f2a28c9a15912d45cb117096bbfd11ae84c45a1aa34eb852ea

build:
  skip: true  # [win or py>=313]
  number: 0

requirements:
  host:
    - python
    - numpy
    - cython >=3.0,<4
  run:
    - python

outputs:
  - name: {{ name }}
    script: build_apache_beam.sh
    requirements:
      build:
        - python                                 # [build_platform != target_platform]
        - cross-python_{{ target_platform }}     # [build_platform != target_platform]
        - grpcio-tools 1.62.1                    # [build_platform != target_platform]
        - cython 0.29.36                         # [build_platform != target_platform]
        - pyyaml >=3.12,<7.0.0                   # [build_platform != target_platform]
        - jinja2 >=2.7.1,<4.0.0                  # [build_platform != target_platform]
        - yapf 0.29.0                            # [build_platform != target_platform]
        - {{ compiler('c') }}
        - {{ stdlib("c") }}
        # osx-arm64 seems to need this for some reason
        - {{ compiler('cxx') }}
        - numpy >=1.14.3,<2.3.0                  # [build_platform != target_platform]
      host:
        - python
        - setuptools
        - grpcio-tools 1.62.1
        - mypy-protobuf 3.5.0
        - distlib 0.3.7
        - cython 0.29.36
        - pyyaml >=3.12,<7.0.0
        - jinja2 >=2.7.1,<4.0.0
        - yapf 0.29.0
        - numpy >=1.14.3,<2.3.0
        - pip
      run:
        - python
        - crcmod >=1.7,<2.0
        - orjson >=3.9.7,<4
        - dill >=0.3.1.1,<0.3.2
        - cloudpickle >=2.2.1,<2.3.dev0
        - fastavro >=0.23.6,<2
        - fasteners >=0.3,<1.0
        - grpcio >=1.33.1,<2,!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<1.66.0
        - python-hdfs >=2.1.0,<3.0.0
        - httplib2 >=0.8,<0.23.0
        - jsonschema >=4.0.0,<5.0.0
        - jsonpickle >=3.0.0,<4.0.0
        - numpy >=1.14.3,<2.3.0
        - objsize >=0.6.1,<0.8.0
        - packaging >=22.0
        - pymongo >=3.8.0,<5.0.0
        - proto-plus >=1.7.1,<2
        - protobuf >=3.20.3,<6.0.0.dev0,!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*
        - pydot >=1.2.0,<2
        - python-dateutil >=2.8.0,<3
        - pytz >=2018.3
        - redis-py >=5.0.0,<6
        - regex >=2020.6.8
        - requests >=2.24.0,<3.0.0
        - sortedcontainers >=2.4.0
        - typing-extensions >=3.7.0
        - zstandard >=0.18.0,<1
        - pyyaml >=3.12,<7.0.0
        - pyarrow >=3.0.0,<17.0.0
        - pyarrow-hotfix <1

    test:
      requires:
        - pip
        - pytest
      files:
        - test.py
      imports:
        - apache_beam
        - apache_beam.coders
        - apache_beam.examples.complete.game
        - apache_beam.examples.complete.juliaset
        - apache_beam.examples.complete.juliaset.juliaset
        - apache_beam.examples.cookbook
        - apache_beam.examples.flink
        - apache_beam.examples.snippets
        - apache_beam.internal
        - apache_beam.internal.gcp
        - apache_beam.io
        - apache_beam.io.flink
        - apache_beam.io.gcp
        - apache_beam.io.gcp.datastore
        - apache_beam.io.gcp.internal
        - apache_beam.io.gcp.tests
        - apache_beam.metrics
        - apache_beam.options
        - apache_beam.portability
        - apache_beam.portability.api
        - apache_beam.runners
        - apache_beam.runners.dataflow
        - apache_beam.runners.direct
        - apache_beam.runners.interactive
        - apache_beam.runners.interactive.display
        - apache_beam.runners.job
        - apache_beam.runners.portability
        - apache_beam.runners.test
        - apache_beam.runners.worker
        - apache_beam.testing
        - apache_beam.testing.benchmarks
        - apache_beam.testing.benchmarks.nexmark
        - apache_beam.testing.benchmarks.nexmark.models
        - apache_beam.testing.benchmarks.nexmark.queries
        - apache_beam.tools
        - apache_beam.transforms
        - apache_beam.typehints
        - apache_beam.utils
      commands:
        - pip check
        - pytest test.py

  - name: {{ name }}-with-gcp
    build:
      noarch: python
      # noarch so just build it once
      skip: true  # [not linux64 or py!=39]
    requirements:
      host:
        - python {{ python_min }}
      run:
        - python >={{ python_min }}
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        # Try match what's in https://github.com/apache/beam/blob/v{{ version }}/sdks/python/setup.py#L268
        - cachetools >=3.1.0,<6
        - google-api-core >=2.0.0,<3
        - google-apitools >=0.5.31,<0.5.32
        - google-auth >=1.18.0,<3
        - google-auth-httplib2 >=0.1.0,<0.3.0
        - google-cloud-datastore >=2.0.0,<3
        - google-cloud-pubsub >=2.1.0,<3
        - google-cloud-pubsublite >=1.2.0,<2
        - google-cloud-storage >=2.18.2,<3
        - google-cloud-bigquery-core >=2.0.0,<4
        - google-cloud-bigquery-storage >=2.6.3,<3
        - google-cloud-core >=2.0.0,<3
        - google-cloud-bigtable >=2.19.0,<3
        - google-cloud-spanner >=3.0.0,<4
        - google-cloud-dlp >=3.0.0,<4
        - google-cloud-language >=2.0,<3
        - google-cloud-videointelligence >=2.0,<3
        - google-cloud-vision >=2,<4
        - google-cloud-recommendations-ai >=0.1.0,<0.11.0
        - google-cloud-aiplatform >=1.26.0,<2.0
        - keyrings.google-artifactregistry-auth
    test:
      imports:
        # not sure what test is useful...
        - apache_beam
      commands:
        - pip check
      requires:
        - python {{ python_min }}
        - pip

#  - name: {{ name }}-with-interactive
#    requirements:
#      host:
#        - python {{ python_min }}
#      run:
#        - python
#        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
#        - facets-overview >=1.0.0,<2
#        - google-cloud-dataproc >=3.0.0,<3.2.0
#        - ipython >=8,<9
#        - ipykernel >=6,<7
#        - ipywidgets >=8,<9
#        - jupyter_client >=6.1.11,!=6.1.13,<8.2.1
#        - timeloop >=1.0.2,<2
#    test:
#      imports:
#        # not sure what test is useful...
#        - apache_beam
#      commands:
#        - pip check
#      requires:
#        - python {{ python_min }}
#        - pip

  - name: {{ name }}-with-aws
    build:
      noarch: python
      # noarch so just build it once
      skip: true  # [not linux64 or py!=39]
    requirements:
      host:
        - python {{ python_min }}
      run:
        - python >={{ python_min }}
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - boto3 >=1.9,<2
    test:
      imports:
        # not sure what test is useful...
        - apache_beam
      commands:
        - pip check
      requires:
        - python {{ python_min }}
        - pip

  - name: {{ name }}-with-azure
    build:
      noarch: python
      # noarch so just build it once
      skip: true  # [not linux64 or py!=39]
    requirements:
      host:
        - python {{ python_min }}
      run:
        - python >={{ python_min }}
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - azure-storage-blob >=12.3.2,<13
        - azure-core >=1.7.0,<2
        - azure-identity >=1.12.0,<2
    test:
      imports:
        # not sure what test is useful...
        - apache_beam
      commands:
        - pip check
      requires:
        - python {{ python_min }}
        - pip

  - name: {{ name }}-with-dataframe
    build:
      noarch: python
      # noarch so just build it once
      skip: true  # [not linux64 or py!=39]
    requirements:
      host:
        - python {{ python_min }}
      run:
        - python >={{ python_min }}
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - pandas >=1.4.3,!=1.5.0,!=1.5.1,<2.3
    test:
      imports:
        # not sure what test is useful...
        - apache_beam
      commands:
        - pip check
      requires:
        - python {{ python_min }}
        - pip

  - name: {{ name }}-with-dask
    build:
      noarch: python
      # noarch so just build it once
      skip: true  # [not linux64 or py!=39]
    requirements:
      host:
        - python {{ python_min }}
      run:
        - python >={{ python_min }}
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - dask >=2024.4.2
        - distributed >=2024.4.2
    test:
      imports:
        # not sure what test is useful...
        - apache_beam
      commands:
        - pip check
      requires:
        - python {{ python_min }}
        - pip

  - name: {{ name }}-with-yaml
    build:
      noarch: python
      # noarch so just build it once
      skip: true  # [not linux64 or py!=39]
    requirements:
      host:
        - python {{ python_min }}
      run:
        - python >={{ python_min }}
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - docstring_parser >=0.15,<1.0
        - jinja2 >=3.0,<3.2
        - pyyaml >=3.12,<7.0.0
        - pandas >=1.4.3,!=1.5.0,!=1.5.1,<2.3
        - virtualenv-clone >=0.5,<1.0
        - js2py >=0.74,<1  # [py<312]
    test:
      imports:
        # not sure what test is useful...
        - apache_beam
      commands:
        - pip check
      requires:
        - python {{ python_min }}
        - pip

  - name: {{ name }}-with-torch
    build:
      noarch: python
      # noarch so just build it once
      skip: true  # [not linux64 or py!=39]
    requirements:
      host:
        - python {{ python_min }}
      run:
        - python >={{ python_min }}
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - pytorch <=1.13.0,<=2.0.0
    test:
      imports:
        - apache_beam
      commands:
        - pip check
      requires:
        - python {{ python_min }}
        - pip

# the libmamba solver couldn't make this work.  It might work with newer
# python versions but I don't have time to investigate
#  - name: {{ name }}-with-tensorflow
#    build:
#      noarch: python
#      # noarch so just build it once
#      skip: true  # [not linux64 or py!=39]
#    requirements:
#      host:
#        - python {{ python_min }}
#      run:
#        - python >={{ python_min }}
#        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
#        - tensorflow >=2.12rc1,<2.13
#    test:
#      imports:
#        - apache_beam
#      commands:
#        - pip check
#      requires:
#        - python {{ python_min }}
#        - pip

# the libmamba solver couldn't install tensorflow, perhaps related to above.  
# It might work with newer python versions but I don't have time to investigate.
#  - name: {{ name }}-with-transformers
#    build:
#      noarch: python
#      # noarch so just build it once
#      skip: true  # [not linux64 or py!=39]
#    requirements:
#      host:
#        - python {{ python_min }}
#      run:
#        - python >={{ python_min }}
#        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
#        - transformers >=4.28.0,<4.49.0
#        # tensorflow 2.12.0 was not built on conda-forge
#        - tensorflow 2.12.1
#        - pytorch >=1.9.0,<2.1.0
#    test:
#      imports:
#        - apache_beam
#      commands:
#        - pip check
#      requires:
#        - python {{ python_min }}
#        - pip

# tensorflow_transform does not appear to be on conda-forge
#  - name: {{ name }}-with-tft
#    build:
#      noarch: python
#      # noarch so just build it once
#      skip: true  # [not linux64 or py!=39]
#    requirements:
#      host:
#        - python {{ python_min }}
#      run:
#        - python >={{ python_min }}
#        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
#        - tensorflow_transform >=1.14.0,<1.15.0
#    test:
#      imports:
#        - apache_beam
#      commands:
#        - pip check
#      requires:
#        - python {{ python_min }}
#        - pip

# transformers 4.25.1 was not build (and is crazy old!)
#  - name: {{ name }}-with-onnx
#    build:
#      noarch: python
#      # noarch so just build it once
#      skip: true  # [not linux64 or py!=39]
#    requirements:
#      host:
#        - python {{ python_min }}
#      run:
#        - python >={{ python_min }}
#        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
#        - onnxruntime 1.13.1
#        - pytorch 1.13.1
#        - tensorflow 2.11.0
#        - tf2onnx 1.13.0
#        - skl2onnx 1.13
#        - transformers 4.25.1
#    test:
#      imports:
#        - apache_beam
#      commands:
#        - pip check
#      requires:
#        - python {{ python_min }}
#        - pip

# datatable 1.0.0 has not been built on conda-forge
#  - name: {{ name }}-with-xgboost
#    build:
#      noarch: python
#      # noarch so just build it once
#      skip: true  # [not linux64 or py!=39]
#    requirements:
#      host:
#        - python {{ python_min }}
#      run:
#        - python >={{ python_min }}
#        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
#        - xgboost >=1.6.0,<2.1.3
#        - datatable 1.0.0
#    test:
#      imports:
#        - apache_beam
#      commands:
#        - pip check
#      requires:
#        - python {{ python_min }}
#        - pip


  - name: {{ name }}-with-tensorflow-hub
    build:
      noarch: python
      # noarch so just build it once
      skip: true  # [not linux64 or py!=39]
    requirements:
      host:
        - python {{ python_min }}
      run:
        - python >={{ python_min }}
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - tensorflow-hub >=0.14.0,<0.16.0
    test:
      imports:
        - apache_beam
      commands:
        - pip check
      requires:
        - python {{ python_min }}
        - pip

about:
  home: https://beam.apache.org
  license: Apache-2.0
  license_family: Apache
  license_file: LICENSE
  summary: 'Apache Beam: An advanced unified programming model'

  description: |
    Apache Beam is an open source, unified model for defining both batch
    and streaming data-parallel processing pipelines. Using one of the open
    source Beam SDKs, you build a program that defines the pipeline. The
    pipeline is then executed by one of Beam’s supported distributed
    processing back-ends, which include Apache Apex, Apache Flink, Apache
    Spark, and Google Cloud Dataflow.
  doc_url: https://beam.apache.org/documentation/
  dev_url: https://github.com/apache/beam

extra:
  recipe-maintainers:
    - sodre
    - aaltay
    - xylar
